{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import snorkel.labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "randchoices = [*range(0,20,1)]\n",
    "weights = [0.1, 0.8, 0.8,0.7,3.6,\n",
    "                                             1.4, 1.7,0.7,59,2.5,\n",
    "                                             15, 0.2, 0.1, 3.5,0.2,\n",
    "                                             1.9, 1.5,3.5,0.3,2.49]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "NUMCLASSES=20\n",
    "\n",
    "\n",
    "def create_single_labelled_LMatrix(numRows):\n",
    "    L = np.empty([numRows,NUMCLASSES])\n",
    "    y = np.empty(numRows)\n",
    "    for i in range(numRows):\n",
    "#         y1 = random.randint(0, NUMCLASSES-1)\n",
    "        r = random.choices(randchoices,weights=weights )\n",
    "        y1 = r[0]\n",
    "        L1 = np.empty(NUMCLASSES)\n",
    "        L1.fill(-1)\n",
    "        L1[y1] = y1\n",
    "        \n",
    "        numlabels = random.randint(0, NUMCLASSES-1)\n",
    "        if (numlabels < 8):\n",
    "            for j in range(numlabels):\n",
    "                y2 = random.randint(0, NUMCLASSES-1)\n",
    "                L1[y2] = y2\n",
    "            \n",
    "        y[i] = y1\n",
    "        L[i] = L1\n",
    "    \n",
    "    return  L, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00         0\n",
      "         0.0       0.09      0.64      0.16        50\n",
      "         1.0       0.18      0.90      0.30       408\n",
      "         2.0       0.18      0.87      0.29       403\n",
      "         3.0       0.19      0.84      0.31       336\n",
      "         4.0       0.92      0.68      0.78      1798\n",
      "         5.0       0.33      0.78      0.46       665\n",
      "         6.0       0.50      0.72      0.59       853\n",
      "         7.0       0.14      0.91      0.25       324\n",
      "         8.0       0.96      0.77      0.85     29533\n",
      "         9.0       0.79      0.68      0.73      1191\n",
      "        10.0       0.98      0.65      0.78      7552\n",
      "        11.0       0.14      0.73      0.23       116\n",
      "        12.0       0.07      0.76      0.13        38\n",
      "        13.0       0.86      0.65      0.74      1755\n",
      "        14.0       0.13      0.75      0.22       107\n",
      "        15.0       0.57      0.74      0.65       911\n",
      "        16.0       0.46      0.72      0.56       799\n",
      "        17.0       0.89      0.65      0.75      1798\n",
      "        18.0       0.13      0.72      0.22       129\n",
      "        19.0       0.80      0.67      0.73      1234\n",
      "\n",
      "    accuracy                           0.73     50000\n",
      "   macro avg       0.44      0.71      0.46     50000\n",
      "weighted avg       0.89      0.73      0.79     50000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srimugunthan/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "L_train1, ytrue = create_single_labelled_LMatrix(50000)\n",
    "\n",
    "lm = snorkel.labeling.LabelModel(cardinality = 20)\n",
    "lm.fit(L_train1,  n_epochs=500,lr=0.001, log_freq=100, seed=123)\n",
    "y_pred = lm.predict(L_train1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytrue, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred[y_pred == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "NUMCLASSES=20\n",
    "def create_multi_labelled_LMatrix(numRows):\n",
    "    L = np.empty([numRows,NUMCLASSES])\n",
    "    y = np.empty(numRows)\n",
    "    for i in range(numRows):\n",
    "        L1 = np.empty(NUMCLASSES)\n",
    "        L1.fill(-1)\n",
    "        numlabels = random.randint(0, NUMCLASSES-1)\n",
    "        for j in range(numlabels):\n",
    "            y1 = random.randint(0, NUMCLASSES-1)\n",
    "            L1[y1] = y1\n",
    "        L[i] = L1\n",
    "    \n",
    "    return  L\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train2 =  create_multi_labelled_LMatrix(15000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train = np.concatenate((L_train1, L_train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = snorkel.labeling.LabelModel(cardinality = 20)\n",
    "lm.fit(L_train,  n_epochs=500,lr=0.001, log_freq=100, seed=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65000, 20)"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = lm.predict_proba(L_train)\n",
    "\n",
    "y_pred_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.utils import probs_to_preds\n",
    "probs = y_pred_prob[:50000]\n",
    "y_pred2 = probs_to_preds(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.02      0.98      0.03        50\n",
      "         1.0       0.35      0.75      0.48       408\n",
      "         2.0       0.26      0.72      0.38       403\n",
      "         3.0       0.19      0.76      0.30       336\n",
      "         4.0       0.92      0.68      0.78      1798\n",
      "         5.0       0.44      0.71      0.54       665\n",
      "         6.0       0.60      0.69      0.64       853\n",
      "         7.0       0.22      0.73      0.34       324\n",
      "         8.0       1.00      0.66      0.79     29533\n",
      "         9.0       0.80      0.68      0.74      1191\n",
      "        10.0       0.98      0.65      0.78      7552\n",
      "        11.0       0.05      0.84      0.09       116\n",
      "        12.0       0.02      0.92      0.03        38\n",
      "        13.0       0.87      0.65      0.74      1755\n",
      "        14.0       0.05      0.84      0.09       107\n",
      "        15.0       0.65      0.70      0.68       911\n",
      "        16.0       0.58      0.69      0.63       799\n",
      "        17.0       0.89      0.65      0.75      1798\n",
      "        18.0       0.06      0.83      0.10       129\n",
      "        19.0       0.81      0.67      0.73      1234\n",
      "\n",
      "    accuracy                           0.67     50000\n",
      "   macro avg       0.49      0.74      0.48     50000\n",
      "weighted avg       0.92      0.67      0.76     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytrue, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred2[y_pred2 == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ltrain2df = pd.DataFrame(L_train2)\n",
    "ltrain2df[\"mask\"] = False\n",
    "ltrain2df[\"truths\"] = -2\n",
    "\n",
    "\n",
    "ltrain1df = pd.DataFrame(L_train1)\n",
    "ltrain1df[\"mask\"] = True\n",
    "ltrain1df[\"truths\"] = ytrue\n",
    "frames = [ltrain1df, ltrain2df]\n",
    "ltraindf = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65000, 22)"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltraindf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.utils\n",
    "df = sklearn.utils.shuffle(ltraindf)\n",
    "\n",
    "# df = ltraindf.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpdf = df.iloc[:, 0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltrain = numpdf.to_numpy()\n",
    "mask = df[\"mask\"]\n",
    "singledf = df[mask]\n",
    "ytrue = singledf[\"truths\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = snorkel.labeling.LabelModel(cardinality = 20)\n",
    "lm.fit(ltrain,  n_epochs=500,lr=0.001, log_freq=100, seed=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65000, 20)"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = lm.predict_proba(ltrain)\n",
    "\n",
    "y_pred_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.utils import probs_to_preds\n",
    "probs = y_pred_prob[mask]\n",
    "y_pred3 = probs_to_preds(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.02      0.98      0.03        50\n",
      "         1.0       0.35      0.75      0.48       408\n",
      "         2.0       0.26      0.72      0.38       403\n",
      "         3.0       0.19      0.76      0.30       336\n",
      "         4.0       0.92      0.68      0.78      1798\n",
      "         5.0       0.44      0.71      0.54       665\n",
      "         6.0       0.60      0.69      0.64       853\n",
      "         7.0       0.23      0.73      0.35       324\n",
      "         8.0       1.00      0.66      0.79     29533\n",
      "         9.0       0.80      0.68      0.74      1191\n",
      "        10.0       0.98      0.65      0.78      7552\n",
      "        11.0       0.05      0.84      0.09       116\n",
      "        12.0       0.02      0.92      0.03        38\n",
      "        13.0       0.87      0.65      0.74      1755\n",
      "        14.0       0.05      0.84      0.09       107\n",
      "        15.0       0.65      0.70      0.68       911\n",
      "        16.0       0.58      0.69      0.63       799\n",
      "        17.0       0.89      0.65      0.75      1798\n",
      "        18.0       0.06      0.83      0.10       129\n",
      "        19.0       0.81      0.67      0.73      1234\n",
      "\n",
      "    accuracy                           0.67     50000\n",
      "   macro avg       0.49      0.74      0.48     50000\n",
      "weighted avg       0.92      0.67      0.76     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(ytrue, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred3[y_pred3 == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
